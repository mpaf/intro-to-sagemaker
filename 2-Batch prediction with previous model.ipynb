{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a file for batch prediction\n",
    "\n",
    "Normally this is the data that would be used as your input data, but we have to create it before from the Iris dataset. Let's using the already split training data set to run Batch prediction on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import pandas as pd\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "data_location = 's3://{}/{}'.format(bucket,\"iris/data/iris_test.csv\")\n",
    "df = pd.read_csv(data_location,header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove the class label from the batch data\n",
    "\n",
    "Since we are running prediction, we don't have the label (first column) beforehand. Our training data is labeled, so we will remove that label and try to infer it from our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchdf = df.drop(columns=0)\n",
    "batchdf.to_csv(\"iris_batch.csv\",header=False,index=False)\n",
    "input_batch = sagemaker_session.upload_data(path='iris_batch.csv', key_prefix='iris/data')\n",
    "batchdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the S3 path to the file that will be used for batch prediction.\n",
    "input_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the batch transformation\n",
    "\n",
    "We will trigger a one off Batch transformation process in SageMaker to transform data that is in our S3 bucket into predicted results. The predicted results will be stored in the same Bucket with key iris/batch_output. Note that this will run an instance with the XGBoost container to infer the flower type for each batch input, and stop it at the end - so it's a great way to save on costs when the use-case does not require an online endpoint.\n",
    "\n",
    "Typically Batch transformation are run on a Lambda with the SageMaker or Boto3 SDKs installed, and triggered on a **schedule** or based on an **event** (e.g. an object was uploaded to S3 containing new data).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normally you would not run batch manually, but trigger the batch prediction on an event \n",
    "# Some possible triggers would be: scheduled, a new file in S3\n",
    "\n",
    "from sagemaker.transformer import Transformer\n",
    "\n",
    "output_path='s3://{}/iris/batch_output'.format(bucket)\n",
    "\n",
    "#model_name = COPY_THE_MODEL_NAME_FROM_PREVIOUS_NOTEBOOK_HERE\n",
    "model_name = \"xgboost-2020-02-24-08-58-21-841\"\n",
    "\n",
    "xgb_batch = Transformer(\n",
    "    base_transform_job_name='iris-batch',\n",
    "    model_name=model_name,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.large',\n",
    "    output_path=output_path)\n",
    "\n",
    "xgb_batch.transform(input_batch,content_type='text/csv',split_type='Line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_batch.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now let's view our predictions\n",
    "import boto3\n",
    "import json\n",
    "s3_client = boto3.client('s3')\n",
    "input_files = s3_client.list_objects(Bucket=bucket,\n",
    "                               Prefix='iris/batch_output/',\n",
    "                               Delimiter='/')['Contents']\n",
    "\n",
    "output_data = pd.concat([ pd.read_csv('s3://{}/{}'.format(bucket, file['Key']), header=None) for file in input_files ])\n",
    "\n",
    "output_data.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
